Namespace(EnvIdex=1, K_epochs=10, Loadmodel=False, Max_train_steps=12500000.0, ModelIdex=300000, T_horizon=512, adv_normalization=False, batch_size=64, clip_rate=0.2, dvc=device(type='cuda'), entropy_coef=0, entropy_coef_decay=0.99, eval_interval=1250.0, gamma=0.99, l2_reg=0, lambd=0.95, lr=0.0001, net_width=64, render=False, save_interval=25000.0, seed=209, write=False)
Random Seed: 209
Env:FightingZombiesDqnDisc  state_dim: 15   action_dim: 7    Random Seed: 209   max_e_steps: 200


| Episode:  0 | Episode reward:  99.7 |
| Episode:  1 | Episode reward:  98.4 |
| Episode:  2 | Episode reward:  98.4 |
| Episode:  3 | Episode reward:  98.9 |
Traceback (most recent call last):
  File "/home/chris/Desktop/MyProjects/PPO-Discrete-Pytorch/main.py", line 131, in <module>
    main()
  File "/home/chris/Desktop/MyProjects/PPO-Discrete-Pytorch/main.py", line 82, in main
    s = env.reset(seed=env_seed) # Do not use opt.seed directly, or it can overfit to opt.seed
  File "/home/chris/Desktop/MyProjects/PPO-Discrete-Pytorch/gym_env.py", line 19, in reset
    self.agent.start_episode()
  File "/home/chris/Desktop/MyProjects/PPO-Discrete-Pytorch/malmo_agent.py", line 64, in start_episode
    self.__safe_wait_for_start()
  File "/home/chris/Desktop/MyProjects/PPO-Discrete-Pytorch/malmo_agent.py", line 279, in __safe_wait_for_start
    time.sleep(0.1)
KeyboardInterrupt
